{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bukHiyfG4Xa1"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_jk9ycLOAMN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn_oRezbk9wo"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9A8-xmmeHfW"
      },
      "source": [
        "## Copy & extract the .zip file into colab workspace `/content/dataset`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuW8bgisOJPh"
      },
      "outputs": [],
      "source": [
        "#os.mkdir(\"dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3QybDbeOnzr"
      },
      "outputs": [],
      "source": [
        "#!cp -av \"/content/drive/MyDrive/BRACU Thesis Groups/Seizure/dataset/Copy of 5s Inter-ictal.zip\" \"/content/dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL8lCPWCQYEu"
      },
      "outputs": [],
      "source": [
        "#!cp -av \"/content/drive/MyDrive/BRACU Thesis Groups/Seizure/dataset/Copy of 5s preictal.zip\" \"/content/dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8h3fcd5plT9"
      },
      "outputs": [],
      "source": [
        "#!unzip \"dataset/Copy of 5s Inter-ictal.zip\" -d \"dataset/interictal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I5OBYaOR8tv",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#!unzip \"dataset/Copy of 5s preictal.zip\" -d \"dataset/preictal\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XE0XSacecUX"
      },
      "source": [
        "## Create a list of dataset file directories (5s windows stored as .npy array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADa_iiBqM6h7",
        "outputId": "82afe85a-34e3-4bf7-877e-e0c4f6b6ff32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples: 35131\n",
            "C:/Users/User/Downloads/Nabiha/Thesis/code files/all patient files/5s interictal file\\chb01_03.edf___(Inter-ictal)___1.npy\n",
            "C:/Users/User/Downloads/Nabiha/Thesis/code files/all patient files/5s interictal file\\chb01_03.edf___(Inter-ictal)___10.npy\n",
            "C:/Users/User/Downloads/Nabiha/Thesis/code files/all patient files/5s interictal file\\chb01_03.edf___(Inter-ictal)___100.npy\n",
            "C:/Users/User/Downloads/Nabiha/Thesis/code files/all patient files/5s interictal file\\chb01_03.edf___(Inter-ictal)___101.npy\n",
            "C:/Users/User/Downloads/Nabiha/Thesis/code files/all patient files/5s interictal file\\chb01_03.edf___(Inter-ictal)___102.npy\n",
            "C:/Users/User/Downloads/Nabiha/Thesis/code files/all patient files/5s interictal file\\chb01_03.edf___(Inter-ictal)___103.npy\n",
            "C:/Users/User/Downloads/Nabiha/Thesis/code files/all patient files/5s interictal file\\chb01_03.edf___(Inter-ictal)___104.npy\n",
            "C:/Users/User/Downloads/Nabiha/Thesis/code files/all patient files/5s interictal file\\chb01_03.edf___(Inter-ictal)___105.npy\n",
            "C:/Users/User/Downloads/Nabiha/Thesis/code files/all patient files/5s interictal file\\chb01_03.edf___(Inter-ictal)___106.npy\n",
            "C:/Users/User/Downloads/Nabiha/Thesis/code files/all patient files/5s interictal file\\chb01_03.edf___(Inter-ictal)___107.npy\n"
          ]
        }
      ],
      "source": [
        "input_dir_interictal = \"C:/Users/User/Downloads/Nabiha/Thesis/code files/all patient files/5s interictal file\"\n",
        "input_dir_preictal = \"C:/Users/User/Downloads/Nabiha/Thesis/code files/all patient files/5s preictal file\"\n",
        "\n",
        "interictal_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir_interictal, fname)\n",
        "        for fname in os.listdir(input_dir_interictal)\n",
        "        if fname.endswith(\".npy\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "preictal_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir_preictal, fname)\n",
        "        for fname in os.listdir(input_dir_preictal)\n",
        "        if fname.endswith(\".npy\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_img_paths = interictal_paths + preictal_paths\n",
        "\n",
        "print(\"Number of samples:\", len(input_img_paths))\n",
        "\n",
        "for input_img_path in input_img_paths[:10]:\n",
        "    print(input_img_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap6KgFqze5z7"
      },
      "source": [
        "## Define parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-b1GnYVe4AM"
      },
      "outputs": [],
      "source": [
        "img_size = (18, 1280) #5s window shape (num_channels, 5 * Fs)\n",
        "num_classes = 2\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AqkIejHffo3"
      },
      "source": [
        "## Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObQRqYdnUWtY"
      },
      "outputs": [],
      "source": [
        "class EEGData(keras.utils.Sequence):\n",
        "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
        "\n",
        "    def __init__(self, batch_size, img_size, input_img_paths):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.input_img_paths = input_img_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_img_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        \"\"\"Returns tuple (input, label) correspond to batch #idx.\"\"\"\n",
        "        i = idx * self.batch_size\n",
        "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
        "        x = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"float32\")\n",
        "\n",
        "        for j, path in enumerate(batch_input_img_paths):\n",
        "            img = np.load(path)\n",
        "            img = (img - img.min())/(img.max() - img.min())\n",
        "            x[j] = np.expand_dims(img, axis=-1)\n",
        "        y = np.zeros((self.batch_size,) + (1,), dtype=\"uint8\")\n",
        "\n",
        "        for j, path in enumerate(batch_input_img_paths):\n",
        "            #print(path)\n",
        "            data_type = path.split(\"/\")[-1].split(\" \")[1]\n",
        "           # print(data_type)\n",
        "            # interictal -> 0\n",
        "            # preictal -> 1\n",
        "\n",
        "            if data_type == \"interictal\":\n",
        "                label = 0\n",
        "            elif data_type == \"preictal\":\n",
        "                label = 1\n",
        "            y[j] = label\n",
        "        return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cke4iyQBa6l2",
        "outputId": "ffaa99e2-4bb4-43ce-da16-fbf9805a497c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(test_gen) 109\n",
            "len(train_gen) 768\n",
            "len(val_gen) 219\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# Split our img paths into a training, validation & test set as 70%, 20% & 10%\n",
        "val_samples = int(len(input_img_paths)*0.2)\n",
        "test_samples = int(len(input_img_paths)*0.1)\n",
        "\n",
        "random.Random(1337).shuffle(input_img_paths)\n",
        "\n",
        "train_input_file_paths = input_img_paths[:-(val_samples+test_samples)]\n",
        "\n",
        "val_input_file_paths = input_img_paths[-(val_samples+test_samples):-test_samples]\n",
        "\n",
        "test_input_file_paths = input_img_paths[-test_samples:]\n",
        "\n",
        "# Instantiate data Sequences for each split\n",
        "train_gen = EEGData(\n",
        "    batch_size, img_size, train_input_file_paths\n",
        ")\n",
        "val_gen = EEGData(\n",
        "    batch_size, img_size, val_input_file_paths\n",
        ")\n",
        "test_gen = EEGData(\n",
        "    batch_size, img_size, test_input_file_paths\n",
        ")\n",
        "print(\"len(test_gen)\",len(test_gen))\n",
        "print(\"len(train_gen)\",len(train_gen))\n",
        "print(\"len(val_gen)\",len(val_gen))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5ootPrUgoBO"
      },
      "source": [
        "## Check one sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1Yzg9woWdsY",
        "outputId": "9a802fef-d335-41b4-c067-017b143a77fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[[0.38059583]\n",
            "   [0.38454744]\n",
            "   [0.390197  ]\n",
            "   ...\n",
            "   [0.3562577 ]\n",
            "   [0.3632931 ]\n",
            "   [0.37288317]]\n",
            "\n",
            "  [[0.36470047]\n",
            "   [0.4905302 ]\n",
            "   [0.55002064]\n",
            "   ...\n",
            "   [0.2995669 ]\n",
            "   [0.29659072]\n",
            "   [0.30958015]]\n",
            "\n",
            "  [[0.405519  ]\n",
            "   [0.34946603]\n",
            "   [0.26909253]\n",
            "   ...\n",
            "   [0.39127672]\n",
            "   [0.41668767]\n",
            "   [0.41805366]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.36509237]\n",
            "   [0.37547064]\n",
            "   [0.40508673]\n",
            "   ...\n",
            "   [0.38112956]\n",
            "   [0.38014165]\n",
            "   [0.373625  ]]\n",
            "\n",
            "  [[0.3789522 ]\n",
            "   [0.41204354]\n",
            "   [0.43062437]\n",
            "   ...\n",
            "   [0.41883466]\n",
            "   [0.4212606 ]\n",
            "   [0.4320816 ]]\n",
            "\n",
            "  [[0.4709625 ]\n",
            "   [0.47114787]\n",
            "   [0.46263647]\n",
            "   ...\n",
            "   [0.32590872]\n",
            "   [0.34530038]\n",
            "   [0.36384436]]]\n",
            "\n",
            "\n",
            " [[[0.6227802 ]\n",
            "   [0.6125198 ]\n",
            "   [0.59757817]\n",
            "   ...\n",
            "   [0.54408264]\n",
            "   [0.5602513 ]\n",
            "   [0.59268004]]\n",
            "\n",
            "  [[0.5400129 ]\n",
            "   [0.535728  ]\n",
            "   [0.56110245]\n",
            "   ...\n",
            "   [0.57082933]\n",
            "   [0.6146771 ]\n",
            "   [0.62622285]]\n",
            "\n",
            "  [[0.675651  ]\n",
            "   [0.6346833 ]\n",
            "   [0.5894367 ]\n",
            "   ...\n",
            "   [0.6768681 ]\n",
            "   [0.6398167 ]\n",
            "   [0.61326265]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.6354846 ]\n",
            "   [0.6143525 ]\n",
            "   [0.5931952 ]\n",
            "   ...\n",
            "   [0.54311526]\n",
            "   [0.5484253 ]\n",
            "   [0.5568462 ]]\n",
            "\n",
            "  [[0.5631558 ]\n",
            "   [0.5396995 ]\n",
            "   [0.5215249 ]\n",
            "   ...\n",
            "   [0.5998488 ]\n",
            "   [0.6072194 ]\n",
            "   [0.62322617]]\n",
            "\n",
            "  [[0.55084157]\n",
            "   [0.5491239 ]\n",
            "   [0.55355775]\n",
            "   ...\n",
            "   [0.6203161 ]\n",
            "   [0.6207626 ]\n",
            "   [0.6139631 ]]]\n",
            "\n",
            "\n",
            " [[[0.5579326 ]\n",
            "   [0.5595359 ]\n",
            "   [0.5603141 ]\n",
            "   ...\n",
            "   [0.57152414]\n",
            "   [0.5719368 ]\n",
            "   [0.5731835 ]]\n",
            "\n",
            "  [[0.590253  ]\n",
            "   [0.59561354]\n",
            "   [0.599877  ]\n",
            "   ...\n",
            "   [0.5600364 ]\n",
            "   [0.55753917]\n",
            "   [0.55512375]]\n",
            "\n",
            "  [[0.56653124]\n",
            "   [0.5693924 ]\n",
            "   [0.5710036 ]\n",
            "   ...\n",
            "   [0.58062446]\n",
            "   [0.58167434]\n",
            "   [0.5818996 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.6142724 ]\n",
            "   [0.6154329 ]\n",
            "   [0.6130977 ]\n",
            "   ...\n",
            "   [0.598236  ]\n",
            "   [0.59785753]\n",
            "   [0.5987314 ]]\n",
            "\n",
            "  [[0.6047845 ]\n",
            "   [0.60945594]\n",
            "   [0.61270154]\n",
            "   ...\n",
            "   [0.5716543 ]\n",
            "   [0.5682051 ]\n",
            "   [0.5649355 ]]\n",
            "\n",
            "  [[0.5708487 ]\n",
            "   [0.5719093 ]\n",
            "   [0.5718773 ]\n",
            "   ...\n",
            "   [0.5382607 ]\n",
            "   [0.5406851 ]\n",
            "   [0.54587173]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.4563386 ]\n",
            "   [0.45442393]\n",
            "   [0.4713474 ]\n",
            "   ...\n",
            "   [0.4879338 ]\n",
            "   [0.5138584 ]\n",
            "   [0.5395633 ]]\n",
            "\n",
            "  [[0.48661843]\n",
            "   [0.46324912]\n",
            "   [0.44715682]\n",
            "   ...\n",
            "   [0.47513783]\n",
            "   [0.47702113]\n",
            "   [0.48270273]]\n",
            "\n",
            "  [[0.6250035 ]\n",
            "   [0.6180815 ]\n",
            "   [0.5998096 ]\n",
            "   ...\n",
            "   [0.4432152 ]\n",
            "   [0.45041373]\n",
            "   [0.4687813 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.5296908 ]\n",
            "   [0.5297551 ]\n",
            "   [0.5273261 ]\n",
            "   ...\n",
            "   [0.46403986]\n",
            "   [0.43109205]\n",
            "   [0.44454327]]\n",
            "\n",
            "  [[0.48620552]\n",
            "   [0.4898713 ]\n",
            "   [0.48819217]\n",
            "   ...\n",
            "   [0.57998276]\n",
            "   [0.56415904]\n",
            "   [0.55314523]]\n",
            "\n",
            "  [[0.5870725 ]\n",
            "   [0.5825427 ]\n",
            "   [0.5750581 ]\n",
            "   ...\n",
            "   [0.40062454]\n",
            "   [0.3957488 ]\n",
            "   [0.39921677]]]\n",
            "\n",
            "\n",
            " [[[0.5679789 ]\n",
            "   [0.5474058 ]\n",
            "   [0.53598154]\n",
            "   ...\n",
            "   [0.43974057]\n",
            "   [0.43119973]\n",
            "   [0.4607286 ]]\n",
            "\n",
            "  [[0.5644592 ]\n",
            "   [0.64837426]\n",
            "   [0.69187874]\n",
            "   ...\n",
            "   [0.6524903 ]\n",
            "   [0.6165099 ]\n",
            "   [0.5660886 ]]\n",
            "\n",
            "  [[0.5937147 ]\n",
            "   [0.62297165]\n",
            "   [0.5457942 ]\n",
            "   ...\n",
            "   [0.3960965 ]\n",
            "   [0.39031392]\n",
            "   [0.43416095]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.4812332 ]\n",
            "   [0.4570054 ]\n",
            "   [0.4458436 ]\n",
            "   ...\n",
            "   [0.5610568 ]\n",
            "   [0.5369614 ]\n",
            "   [0.49867404]]\n",
            "\n",
            "  [[0.3999098 ]\n",
            "   [0.37142092]\n",
            "   [0.34853002]\n",
            "   ...\n",
            "   [0.5727932 ]\n",
            "   [0.53996456]\n",
            "   [0.49998343]]\n",
            "\n",
            "  [[0.54916334]\n",
            "   [0.5576778 ]\n",
            "   [0.5577446 ]\n",
            "   ...\n",
            "   [0.32663244]\n",
            "   [0.34999   ]\n",
            "   [0.3872478 ]]]\n",
            "\n",
            "\n",
            " [[[0.5123637 ]\n",
            "   [0.5077542 ]\n",
            "   [0.49859598]\n",
            "   ...\n",
            "   [0.51465505]\n",
            "   [0.5086014 ]\n",
            "   [0.5122106 ]]\n",
            "\n",
            "  [[0.5055416 ]\n",
            "   [0.4971897 ]\n",
            "   [0.50064343]\n",
            "   ...\n",
            "   [0.29401395]\n",
            "   [0.41520584]\n",
            "   [0.5662732 ]]\n",
            "\n",
            "  [[0.4666646 ]\n",
            "   [0.45532298]\n",
            "   [0.45530975]\n",
            "   ...\n",
            "   [0.7249648 ]\n",
            "   [0.8500889 ]\n",
            "   [0.8051803 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.4962461 ]\n",
            "   [0.4705316 ]\n",
            "   [0.4554462 ]\n",
            "   ...\n",
            "   [0.56432796]\n",
            "   [0.48271245]\n",
            "   [0.39976466]]\n",
            "\n",
            "  [[0.50743204]\n",
            "   [0.5086625 ]\n",
            "   [0.5100478 ]\n",
            "   ...\n",
            "   [0.51988816]\n",
            "   [0.51509583]\n",
            "   [0.50958145]]\n",
            "\n",
            "  [[0.5088153 ]\n",
            "   [0.507378  ]\n",
            "   [0.5081515 ]\n",
            "   ...\n",
            "   [0.49929017]\n",
            "   [0.50493354]\n",
            "   [0.51213366]]]]\n",
            "(32, 18, 1280, 1)\n",
            "1.0\n",
            "0.0\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n",
            "(32, 1)\n",
            "1\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "X_sample, y_sample = train_gen[0]\n",
        "print(X_sample)\n",
        "print(X_sample.shape)\n",
        "print(X_sample.max())\n",
        "print(X_sample.min())\n",
        "print(y_sample)\n",
        "print(y_sample.shape)\n",
        "print(y_sample.max())\n",
        "print(y_sample.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyCe1SHwimLi"
      },
      "source": [
        "## Define the CNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptxf3FJJb9S8",
        "outputId": "2d9edb09-e253-4c5d-b7b0-629c94fccc9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 18, 1280, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 18, 1280, 32)      320       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 18, 1280, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 9, 640, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 9, 640, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 9, 640, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 320, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 320, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 4, 320, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 160, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 2, 160, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 160, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 80, 256)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 390,017\n",
            "Trainable params: 389,057\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def get_model(img_size):\n",
        "\n",
        "    inputs = keras.Input(shape=img_size + (1,))\n",
        "\n",
        "    x = layers.Conv2D(32, 3, strides=1, padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool2D((2,2))(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, strides=1, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool2D((2,2))(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 3, strides=1, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool2D((2,2))(x)\n",
        "\n",
        "    x = layers.Conv2D(256, 3, strides=1, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool2D((2,2))(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = layers.Dense(64, activation = \"relu\")(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    x = layers.Dense(32, activation = \"relu\")(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Build model\n",
        "model = get_model(img_size)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CyQ5tnhoGkE"
      },
      "source": [
        "## Plot the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-M779Lq9nhiQ",
        "outputId": "af06dacf-7a8c-422f-e4b3-c3d1a805e895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
          ]
        }
      ],
      "source": [
        "#  tf.keras.utils.plot_model(\n",
        "#      model,   to_file=\"model.png\",\n",
        "#      show_shapes=True,\n",
        "#      show_dtype=False,\n",
        "#      show_layer_names=True,\n",
        "# #     rankdir=\"TB\",\n",
        "# #     expand_nested=False,\n",
        "# #     dpi=96,\n",
        "# #     layer_range=None,\n",
        "# #     show_layer_activations=False,\n",
        "#  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E_pzJWv2MFa"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjokE7Jejxhj",
        "outputId": "67c0164e-34fb-43dc-fcac-7acb5a9eb006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "768/768 [==============================] - 321s 417ms/step - loss: 0.5930 - accuracy: 0.6953 - recall: 0.5257 - precision: 0.6568 - val_loss: 0.5871 - val_accuracy: 0.7041 - val_recall: 0.4236 - val_precision: 0.7352\n"
          ]
        }
      ],
      "source": [
        "epochs = 1 #50\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"), # for saving the weights after each epoch\n",
        "    keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,\n",
        "    restore_best_weights=True,), # for stopping the training when performance stops improving\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.1, patience=5) # reduce learing rate by a factor of 10 when stops improving\n",
        "\n",
        "]\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision()\n",
        "],\n",
        ")\n",
        "history = model.fit(\n",
        "    train_gen, epochs=epochs, callbacks=callbacks, validation_data=val_gen,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es9WTpH32VUG"
      },
      "source": [
        "## Evaluate on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMK2MPkMhD4A",
        "outputId": "d68b6bc2-0f99-47a0-8015-1d059317f54e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "109/109 [==============================] - 10s 90ms/step - loss: 0.5862 - accuracy: 0.7122 - recall: 0.4306 - precision: 0.7432\n",
            "test loss, test acc, test recall, test precision: [0.5861572623252869, 0.7121559381484985, 0.4306151568889618, 0.7432098984718323]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(test_gen, batch_size=batch_size)\n",
        "print(\"test loss, test acc, test recall, test precision:\", results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Io0WYRm2RR8"
      },
      "source": [
        "## Plot training profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXCACMbEzleD"
      },
      "outputs": [],
      "source": [
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "precision = history.history[\"precision\"]\n",
        "val_precision = history.history[\"val_precision\"]\n",
        "\n",
        "recall = history.history[\"recall\"]\n",
        "val_recall = history.history[\"val_recall\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtXEOLbdH1Mj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(loss, 'r', label=\"train loss\")\n",
        "plt.plot(val_loss, 'b', label=\"val loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylim((0, 1))\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(accuracy, 'r', label=\"train accuracy\")\n",
        "plt.plot(val_accuracy, 'b', label=\"val accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylim((0, 1))\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(precision, 'r', label=\"train precision\")\n",
        "plt.plot(val_precision, 'b', label=\"val precision\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylim((0, 1))\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(recall, 'r', label=\"train recall\")\n",
        "plt.plot(val_recall, 'b', label=\"val recall\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylim((0, 1))\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHRRmagU2jiP"
      },
      "outputs": [],
      "source": [
        "# history2 = model.fit(\n",
        "#     train_gen, epochs=epochs, callbacks=callbacks, validation_data=val_gen,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB3z6ryHgPxb"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veIlJXYgH1Mj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q6LJUjBH1Mj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}